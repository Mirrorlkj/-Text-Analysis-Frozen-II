---
title: "Frozen2 Review - Sentiment Analysis"
author: "Kejing Li"
date: "11/26/2019"
output: 
  github_document:
    toc: true
    toc_depth: 3
---

# 1.Introduction 

In this report, I will conduct text analysis, especially sentiment analysis on the reviews of the movie Frozen II. The review data were obtained by scraping([see code here](scrape.R)) three major English review websites:Rotten Tomatoes, IMDb(Internet MovieDatabase) and Metacritic. 

I am interested in seeing the overall comment on the film as well as the differences across each movie review websites. Though the three websites all serve as movie review platforms and have certain extent of popularity, the critics of each website can be quite different: Rotten Tomatoes largely rely on the opinions of professional critics, IMDB uses a system of ratings from the general public, Metacritic only open to mainstream media such as *The Guardianand*、*New York Times* and other professional film critics.

```{r setup, include=FALSE}
# Set global options
# Hide all codes, messages and warnings
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
# Set figure options for better display                      
                      fig.width = 6,
                      fig.asp = 0.618,
                      fig.align = "center",
                      out.width = "70%",
                      out.height = "70%")
#load required packages
library(tidyverse)
library(tm)
library(here)
library(tidytext)
library(knitr)
library(kableExtra)
library(scales)
library(textdata)
library(reshape2)
library(wordcloud)

#set default theme and modify the font size
theme_set(theme_bw(base_size = 11))
```

```{r text_process, include = FALSE, cache = TRUE}
all_reviews <- read.csv(here("data","reviews.csv"))

all_reviews$reviews <- all_reviews$reviews%>%
  str_to_lower(locale = "en") %>% #Converting to lowercase 
  #text processing
  removePunctuation()%>% #Removing punctuation 
  removeNumbers()%>% #Removing numbers
  removeWords(stopwords("en"))#Removing "stopwords"

#another way to remove stopwords
all_reviews <- all_reviews %>%
  anti_join(stop_words, by = c("reviews" = "word"))

#keep only alphanumeric characters or spaces
all_reviews$reviews <- gsub(pattern = "[^[:alnum:][:space:]]", " ", all_reviews$reviews)
#remove the name of the film(topic)
all_reviews$reviews <- gsub(pattern = "frozen", "", all_reviews$reviews)
all_reviews$reviews <- gsub(pattern = "film", "", all_reviews$reviews)
all_reviews$reviews <- gsub(pattern = "movie", "", all_reviews$reviews)
```

# 2.Text Analysis

##  2.1 Word Frequency

### All websites
I counted the frequency of each word in the dataset and the results are as follows. The word “ii” appears most frequently in the movie reviews. Combined with other words of high frequency like “one” and “sequel”, it is quite evident that the people judge the movie heavily rely on the fact that it is a sequel movie. There may be a tendency Frozen II is appraised good or bad against Frozen I.  Besides, “Disney” also appears in the reviews quite often, indicating the significant brand effect of Frozen II.  

```{r word_count_table}
#break the text into individual tokens
reviews_word <- all_reviews%>%
  unnest_tokens(word, reviews)

#count the word frequency
count_word <- reviews_word %>%
  count(word, sort = TRUE)
kable(head(count_word, 10),
      col.names = c("Word","Number"),
      align = "c",
      caption = "Frozen II Review Word Count")%>%
      add_footnote("Source: IMDb, Metacritic, Rotten tomatoes")

```

```{r word_count_graph}
#plot the word frequency
count_word %>%
  filter(n >= 50) %>%
  ggplot(aes(reorder(word, n), n)) +
  geom_col(fill = "cadetblue3") +
  coord_flip()+
  labs(y = "Count",
       x = NULL,
       title = "The common words in Frozen II review",
       caption = "Source: IMDb, Metacritic, Rotten tomatoes")

```

### Across websites
Next, I compared the word frequencies across the three different websites, as shown in the figure below.

Words that are close to the line in these plots have similar frequencies in both sets of texts, for example, in both Rotten Tomatoes and Metacritic reviews (“original”, “movie” at the middle). Words that are far from the line are words that are found more in one set of texts than another. For example, in the Rotten Tomato-IMDB panel, words like “bad”, “love” and “fun” are found in Rotten Tomatoes reviews but not much in the IMDB, while words like “first”  are found in the IMDB texts but not the Rotten Tomatoes. In comparing Rotten Tomatoes with Metacritic, Rotten Tomatoes reviewers use words like “love” and “animation” that Metacritic critics does not.

Overall, notice in the following figure that the words extend to lower frequencies in the Rotten Tomatoes-IMDB panel than in the Rotten Tomatoes-Metacritic panel; there is empty space in the Rotten Tomatoes-IMDB panel at low frequency. These characteristics indicate that Rotten Tomatoes and the IMDB critics use more similar words than Rotten Tomatoes and Metacritic. Also, we see that not all the words are found in all three websites of reviews and there are fewer data points in the panel for Rotten Tomatoes and Metacritic.


```{r}
#calculate the frequency for each word in different sides 
word_freq <- reviews_word %>%
  count(site, word, sort = TRUE ) %>%
  group_by(site) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n)%>%
#tidy the df for plotting afterwards
  pivot_wider(names_from = site, values_from = proportion) %>% 
  pivot_longer(names_to = "site", values_to = "proportion", "imdb":"metacritic")

#create a value for labeling the facet levels 
site_labs <- c("IMDB",
             "Metacritic")
names(site_labs) <- c("imdb","metacritic")

# compare the word frequencies among 3 sites
ggplot(word_freq, aes(x = proportion, y = rotten_tomatoes, color = abs(rotten_tomatoes
- proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.01), low = "cadetblue3", high = "gray75") +
  facet_wrap(~site, ncol = 2, labeller = labeller(site = site_labs)) +
  theme(legend.position="none") +
  labs(y = "Rotten Potatoes",
       x = NULL,
       title = "Comparing the word frequencies of three sites",
       caption = "Source: IMDb, Metacritic, Rotten tomatoes")

```


## 2.2 Sentiment Analysis 

### Binary sentiments

By conducting a binary sentiment analysis, we can see from the table that the positive words outnumber the negative ones. Generally speaking, reviewers tend to give positive comments on the movie.
```{r bing}
reviews_word %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE)%>%
  group_by(sentiment) %>%
  count()%>%
  kable(col.names = c("Sentiment","Number"),
      align = "c",
      caption = "Binary sentiment of Frozen II Review")%>%
      add_footnote("Source: IMDb, Metacritic, Rotten tomatoes")
```

### Categorical sentiments

The above graph depicts the top 10 words contributing to each sentiment seperately. The categorical word counts reveal that **anticipation**, **joy** and **positive** are dominant sentiments of the Frozen II, this finding is consistent with the binary sentiment analysis, which jointly explain that the film has a deightful and positive theme. In contrast, negative sentiments such as anger, disgust, fear and sadness have relatively low counts. 

```{r nrc, fig.width = 10, out.width = "100%", out.height = "100%"}
reviews_word %>%
  inner_join(get_sentiments("nrc")) %>%
  count(word, sentiment, sort = TRUE)%>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ggplot(aes(reorder(word, n), n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free", ncol = 5) +
  labs(title = "Categorical sentiments of Frozen II Review",
       subtitle = "NRC sentiment dictionary",
       y = "Sentiments",
       x = NULL,
       caption = "Source: IMDb, Metacritic, Rotten tomatoes") +
  coord_flip()
```

### Emotional Score 
So far, we have concluded that the film has a postive theme, however, the positivity could vary across websites. By assigning different values to words using AFINN sentiment dictionary, we are able to quantify this difference as fllows. The Rotten Tomatoes score highest amongst three, suggesting its reviews are mostly positive. While the Metacritic has a lower score, though still positive. The reviews on Metacritic may not show as strong positive emotions as on the Rotten Tomatoes. IMDB is somewhere in the middle.

```{r emotional_score}
reviews_word %>% 
  inner_join(get_sentiments("afinn")) %>%
  group_by(site) %>%
  summarize(value = sum(value)) %>%
  ggplot(aes(site, value)) +
  geom_col(fill = "cadetblue3") +
  geom_text(aes(label = value, vjust = 0))+
  scale_x_discrete(labels = c("IMDB", "Metacritic", "Rotten tomatoes"))+
  labs(title = "Emotional Score of Frozen II",
       subtitle = "AFINN sentiment dictionary",
       x = "Websites",
       y = "Emotional Score",
       caption = "Source: IMDb, Metacritic, Rotten tomatoes") +
  theme(legend.position = "none")
```

### Word Clouds

Finally, to get a more intuitive results, let's take a look at the comparison of the negative and positive words in the wordclouds. On the negative side, *grief*, *risks* and *hard* may reflect the plots of Frozen II. On the other hand, it is reasonabe to conjecture words like *bad*, *confusing* and *boring* are come from the negative reviews of the film. Similarly, *love*, *magic* and *beauty* are more likely derived from the theme Frozen II intending to get across. Words like *enjoyable*, *like* and *nice* reflect the critics' appreciation of the movies. 
```{r wordcoulds}
set.seed(1234)   # ensure reproducibility of the wordcloud

reviews_word %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("cadetblue4", "cadetblue3"),
                   max.words = 100)
```

# 3. Conclusion

In a nutshell, Frozen II receives positive comments from the audiences, both professionals and general publics. Still, discrepancy bewteen different websites can still be detected. Specifically, Metacritic is the most strict with the movie; critics from Rotten Tomatoes and IMDB share more similar attitudes. Ultimately, the movie succeeds in communicating a lively, delightful and hopeful mood. 
